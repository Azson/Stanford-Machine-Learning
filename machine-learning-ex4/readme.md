##ex4 笔记
问题先不着急做，先把输入输出看明白</br>

#在进行下列代码前，先cd 到作业目录
1.load('ex4data1.mat')
这时候查看自己的工作区间可以观察到多了X和y变量，也就是样例的输入以及分类结果</br>

2.通过size函数以及输出X,y的部分数据，可以观察到X，y就是课堂上讲的那样的格式，X表示5000条数据，每行表示一个20X20的数字灰度图（不过已经进行缩放）,然后观察y的值发现就是对应样例的数字表示，但我们知道逻辑分类中，这种类别特征的数值是没有意义的，我们仅需要知道他是属于哪一类，所以可以使用one-hot编码（----Line 67-71）</br>

octave:3> load('ex4data1.mat')
octave:4> size(X)
ans =

   5000    400

octave:5> size(y)
ans =

   5000      1

octave:6> X(1, 1:10)
ans =

   0   0   0   0   0   0   0   0   0   0

octave:7> y(1:5, 1)
ans =

   10
   10
   10
   10
   10

3.Feedforward and Cost Function</br>
这部分结合ex4.pdf的第四页的图，应该是没有什么问题，按步骤来把z,a求出来，要注意的是输入层和隐藏层多需要多加“1”值作为第一个元素，并通过Theta矩阵运算传递给下一层（----Line 65-66）</br>

计算cost function，对octave用得还不熟，就还是用for循环稳一点(--Line 73-79)</br>
虽然这部分不需要正规化J，但我还是加了</br>
J = -J/m + lambda/2/m*(sum(sum(Theta1(:, 2:end) .^ 2)) + sum(sum(Theta2(:, 2:end) .^ 2)))

因为不需要的话lambda值是0，对结果不影响

###正规化的时候要注意Theta0不需要考虑惩罚，对应octave下标从2开始计算

4.sigmoid gradient</br>
这个应该不用说了，证明我也不会，不过don't worry about it!

5.Radom Initialization
课堂上说的很清楚了，不要初始化0就行，最好都初始化到-a,a]，a<=1

6.Backpropagation
在课堂上以及小节中都有这个算法的总结，不稳的话按描述一步一步实现吧！
####唯一要注意的事是课堂上讲的z2是包括第一个元素的，也就是“1”元素，但是这个元素计算本层的a向量需要再加一列新的"1"
计算theta梯度变换的时候要注意加入的theta项第一列不需要考虑

####7.本案例还有挺多值得去看的代码，比如displayData.m可以把灰度矩阵还原成图像，这个在做有关图像的问题是时候是必备手段